TECHNICAL FIELD Embodiments of the present invention relate to a storage device and a storage control method.
2. Description of the Related Art In a storage device called a solid state drive (SSD) that includes a nonvolatile semiconductor memory such as a flash memory and has an interface similar to a hard disk drive (HDD), a unit of data erasing and a unit of data reading / writing are different. .
As an example, the unit of data erasure is a physical block, and the unit of data read / write is a smaller cluster.
One physical block includes many word lines, one word line includes many pages, and one page includes a plurality of clusters.
In an SSD, as data rewriting progresses, the possibility that valid clusters and invalid clusters are mixed in a physical block increases.
An effective cluster is a cluster whose physical address is specified by a logical address / physical address conversion table, and an invalid cluster is a cluster whose physical address is not specified by a logical address / physical address conversion table.
When such physical blocks increase, the storage area cannot be used effectively.
In order to effectively use the storage area, a process called compaction or garbage collection (hereinafter, referred to as garbage collection or GC) is performed.
In garbage collection, in order to increase the number of free blocks from which data has been deleted, data of all valid clusters in a logical block including physical blocks in which valid clusters and invalid clusters are mixed (referred to as GC source logical blocks) is deleted. Is moved to a completed logical block (referred to as a GC destination logical block).
All data in the GC source logical block in which data of all valid clusters has been moved to the GC destination logical block is deleted.
The erased GC source logical block is released as a free block, and can be reused as a GC destination logical block.
When reading data of a cluster in a GC source logical block, an error may occur in the read data and the error may not be correctable.
In this case, it is impossible to determine whether the cluster from which data has been read is a valid cluster or an invalid cluster.
Therefore, if a read error occurs in the data of a certain cluster and the error cannot be corrected, garbage collection cannot be performed, the data of the GC source logical block cannot be erased, and the GC source logical block is It cannot be reused as a block.
Prior Art Documents Patent Documents Patent Document 1 JP 2013-200722 A Patent Document 2 JP 2013-174975 A Patent Document 3 U.S. Patent No. 8825946 Patent Document 4 Patent No. 6313242 Patent Document 5 U.S. Patent Application Publication In the conventional storage device, when reading data of the cluster of the GC-source logical block, when a read error occurs, and the error is uncorrectable, There is a risk that GC destination logical blocks are exhausted and garbage collection cannot be executed.
An object of the present invention is to provide a storage device and a storage control method that can secure a GC-source logical block even when an uncorrectable read error occurs and can execute garbage collection.
According to an embodiment, a storage device has a plurality of physical blocks, each physical block has a plurality of clusters, data is erased in units of physical blocks, and data is erased in units of clusters. A first table for storing a relationship between a nonvolatile memory to be read or written, a logical address specified by an external device, and a physical address of the nonvolatile memory corresponding to the logical address; and a plurality of nonvolatile memories. The logical blocks to which the physical blocks are allocated, the second table storing the relationship between the plurality of physical blocks, and moving data read from all valid clusters of the garbage collection source logical block to the garbage collection destination logical block, Erases all data in the garbage collection source logical block, and deletes the first And a controller for updating, comprises a.
The controller creates a new logical block when data read from the cluster of the garbage collection source logical block is uncorrectable, and erases all data of a plurality of physical blocks assigned to the garbage collection source logical block. Then, the plurality of physical blocks from which data has been erased are allocated to the new logical blocks, and the second table is updated so that physical blocks are not substantially allocated to the garbage collection source logical blocks.
BRIEF DESCRIPTION OF THE DRAWINGS FIG. 1 is a block diagram showing a configuration of an example of a storage device according to an embodiment;
FIG. 2 is a diagram illustrating the relationship between physical blocks, logical blocks, and pseudo physical clusters.
FIG. 3 is a diagram showing an example of the LUT 56.
FIG. 4 is a flowchart showing an example of a garbage collection process.
FIG. 5 is a diagram showing an example of a state change of the logical block table 58.
6 is a diagram illustrating an example of garbage collection.
7 is a diagram illustrating an example of garbage collection.
FIG. 8 is a diagram illustrating an example of garbage collection when a GC destination logical block is exhausted.
9 is a diagram illustrating an example of garbage collection when the GC destination logical block is exhausted.
10 is a diagram illustrating an example of a garbage collection to avoid exhaustion of the GC destination logical block.
FIG. 11 is a diagram illustrating an example of garbage collection for avoiding depletion of a GC destination logical block.
FIG. 12 is a diagram illustrating another example of garbage collection for avoiding depletion of a GC destination logical block.
FIG. 13 is a diagram illustrating another example of garbage collection for avoiding depletion of a GC destination logical block.
BEST MODE FOR CARRYING OUT THE INVENTION Hereinafter, embodiments will be described with reference to the drawings.
The disclosure is merely an example, and the present invention is not limited to the contents described in the following embodiments.
Variations readily conceivable to those skilled in the art are, of course, within the scope of the disclosure.
In order to make the description clearer, in the drawings, the size, shape, and the like of each part may be schematically represented by being changed from the actual embodiment.
In a plurality of drawings, corresponding elements are denoted by the same reference numerals, and detailed description may be omitted.
FIG. 1 is a block diagram illustrating a configuration of an example of the SSD 20 according to the embodiment.
The SSD 20 is a semiconductor storage device configured to write data to a nonvolatile semiconductor memory and read data from the nonvolatile semiconductor memory.
The SSD 20 is connected to the host 10.
The host 10 accesses the SSD 20, writes data to the SSD 20, and reads data from the SSD 20.
The host 10 may be a server (also referred to as a storage server) that stores a large amount of various data in the SSD 20, or may be a personal computer.
The SSD 20 can be used as a main storage of the host 10.
The SSD 20 may be built in the host 10, or may be connected to the host 10 via a cable or a network.
The SSD 20 includes a controller 22, a NAND flash memory (hereinafter, referred to as a flash memory) 24, and a RAM 26.
The controller 22 includes a host interface (I / F) 32, a CPU 34, a NAND interface (I / F) 36, and a RAM interface (I / F) 38.
The CPU 34, the host I / F 32, the NAND I / F 36, and the RAM I / F 38 can be connected to the bus line 40.
The controller 22 may be configured by a CPU that operates according to software, or may be configured by a circuit such as a system-on-chip (SoC), an ASIC, an FPGA, or the like.
The host I / F 32 for electrically interconnecting the host 10 and the SSD 20 includes, for example, Small Computer System Interface (SCSI) (registered trademark), PCI Express (registered trademark) (PCIe (registered trademark) ), Serial Attached SCSI (SAS) (registered trademark), Serial Advanced Technology Attachment (SATA) (registered trademark), Non Volatile Memory Express (NVMe (registered trademark)), UniversalSeri alBus Standards such as (USB) (registered trademark) may be used, but are not limited thereto.
The host I / F 32 functions as a circuit that receives various commands from the host 10, for example, I / O commands, various control commands, and the like.
The I / O command may include a write command, a read command, and the like.
The flash memory 24 as a non-volatile semiconductor memory is, for example, a NAND flash memory, but is not limited to a NAND flash memory, and may be another non-volatile semiconductor memory, for example, a NOR flash memory, an MRAM (Magnet oscillator memory). It may be composed of a Pseudo random access memory (PRAM), a phase change random access memory (PRAM), a resistive random access memory (ReRAM), or a ferroelectric random access memory (FeRAM).
Flash memory 24 may include multiple flash memory chips (ie, multiple flash memory dies).
Each flash memory chip includes a memory cell array including a plurality of memory cells arranged in a matrix.
The flash memory 24 may be a two-dimensional NAND flash memory or a three-dimensional NAND flash memory.
Each chip includes a plurality of physical blocks including a plurality of nonvolatile memory cells.
In the flash memory 24, data is collectively erased in units of physical blocks.
That is, the physical block is an area of a data erase unit.
Data read / data write is performed in cluster units.
There is a logical address (LBA) range as a concept on the logical address space corresponding to the cluster.
One cluster includes data associated with one logical address range, or data associated with a part of one logical address range.
Reading and writing of the flash memory 24 are controlled by the controller 22.
The flash memory 24 is connected to the NAND I / F 36.
One or more bits of data can be stored in a memory cell.
Examples of flash memory configured to be able to store multiple bits per memory cell include multi-level cells (Multi-Level Cell (MLC) or Four-Level Cell) that can store 2 bits of data per memory cell. (4LC)) Flash memory, triple-level cell (Triple-LevelCell (called TLC), or Eigt-LevelCell (called 8LC)) flash capable of storing 3 bits of data per memory cell This includes a memory, a quad-level cell (referred to as QLC) or a Sixteen-Level Cell (referred to as 16LC) flash memory capable of storing 4-bit data per memory cell, and the like.
Flash memories configured to store one bit per memory cell are referred to as single-level cell (Single-Level Cell (SLC or 2LC)) flash memories.
The RAM 26 is composed of a volatile memory such as a DRAM or an SRAM, and may be built in the controller 22 instead of being provided outside the controller 22.
The RAM 26 has a write buffer 52 that is a buffer area for temporarily storing data written to the flash memory 24 and a read buffer that is a buffer area for temporarily storing data read from the flash memory 24. 54, a look-up table (referred to as LUT) 56 functioning as an address conversion table (also referred to as a logical address / physical address conversion table), and a logical block table 58 indicating an assignment relationship between logical blocks and physical blocks.
The LUT 56 manages the mapping between the logical cluster address and the pseudo physical cluster address.
The RAM 26 is connected to the RAM I / F 38.
The controller 22 may function as a flash translation layer (FTL) configured to perform data management and block management of the flash memory 24.
The data management performed by the FTL includes (1) management of mapping information indicating a correspondence between a logical address (logical cluster address) of the SSD 20 and a physical address (pseudo physical cluster address) of the flash memory 24, 2) Processing for hiding read / write in cluster units and erase operation in block units is included.
The logical address is an address specified by the host 10 to address the SSD 20.
Management of the mapping between the logical address and the physical address is performed using the LUT 56.
The controller 22 uses the LUT 56 to manage the mapping between the logical address and the physical address in cluster size units.
The physical address corresponding to a certain logical address indicates a physical storage position in the flash memory 24 to which data specified by the logical address has been written.
The LUT 56 may be loaded from the flash memory 24 to the RAM 26 when the power of the SSD 20 is turned on.
The CPU 34 can function as a read control unit 42, a write control unit 44, a garbage collection (GC) control unit 46, and the like.
Note that some or all of the read control unit 42, the write control unit 44, and the GC control unit 46 may be realized by dedicated hardware in the controller 22.
The write control unit 44 performs error correction encoding of the write data, and writes the encoded data to the flash memory 24.
The read control unit 42 performs error correction decoding on data read from the flash memory 24, and corrects errors in the read data.
The error correction encoding and the error correction decoding may be realized by dedicated hardware in the controller 22.
The GC control unit 46 executes garbage collection at appropriate timing.
The write control unit 44 writes the update data corresponding to a certain logical address to another cluster instead of the cluster specified by the physical address corresponding to this logical address.
Then, the write control unit 44 updates the LUT 56 and associates this logical address with a physical address designating this another cluster.
As a result, the previous data is not read, and the cluster storing the previous data is invalidated.
Block management includes bad block management, wear leveling, garbage collection, and the like.
The CPU 34 is a processor configured to control the host I / F 32, the NAND I / F 36, and the RAM I / F 38.
The CPU 34 performs various processes by executing a control program (firmware) stored in a not-shown ROM or the like.
The CPU 34 can execute command processing for processing various commands from the host 10 in addition to the above-described FTL processing.
The operation of the CPU 34 is controlled by the above-described firmware executed by the CPU 34.
Note that part or all of the FTL processing and command processing may be executed by dedicated hardware in the controller 22.
FIG. 2 is a diagram illustrating the relationship between physical blocks, logical blocks, and pseudo physical clusters.
As described above, the NAND chip includes a plurality of physical blocks, and the plurality of physical blocks are allocated to one logical block.
The plurality of physical blocks allocated to one logical block may be a plurality of physical blocks included in a single chip or a plurality of physical blocks included in different chips.
The number of physical blocks allocated to one logical block may be constant regardless of the logical block, or may be different depending on the logical block.
A plurality of pseudo physical clusters are assigned to one logical block.
Information stored in one pseudo physical cluster includes user data (for example, 4 KiB) and a redundant part (for example, 12 bytes).
The redundant part includes a logical cluster address and other information.
The pseudo physical cluster address includes information indicating which logical block the pseudo physical cluster is included in, and the number of the pseudo physical cluster from the first pseudo physical cluster in the logical block, that is, the pseudo physical cluster. Indicating the relative position in the logical block.
When accessing the pseudo physical address, the host 10 specifies a logical cluster address.
The physical address corresponding to the logical address, that is, information indicating the mapping between the logical cluster address and the pseudo physical cluster address is stored in the LUT 56.
FIG. 3 shows an example of the LUT 56.
The LUT 56 stores the pseudo physical cluster address, and the index of the pseudo physical cluster address corresponds to the logical cluster address.
The logical cluster address is represented by index × cluster size (4 KiB).
4KiB is a logical cluster size, and a physical cluster size is 4KiB + 12Bytes.
When the index is obtained by dividing the logical cluster address given by the host 10 by the cluster size, a pseudo physical cluster address corresponding to the logical cluster address is obtained.
For example, if the logical cluster address in the redundant part in the information stored in the pseudo physical cluster A specified by the pseudo physical cluster address PC3 of the index 3 corresponds to the index 3, the pseudo physical cluster A is a valid cluster. It is.
Similarly, when the logical cluster address in the redundant part in the information stored in the pseudo physical cluster B specified by the pseudo physical cluster address PCm of the index m corresponds to the index m, the pseudo physical cluster B is valid. It is a cluster.
On the other hand, the pseudo physical cluster C not specified from the LUT 56 is an invalid cluster.
As described above, by examining all the pseudo physical cluster addresses of the LUT 56, it is possible to determine whether the pseudo physical cluster is a valid cluster or an invalid cluster. Or invalid cluster.
For example, the pseudo physical cluster address of the pseudo physical cluster D is PCd, the logical cluster address of the redundant part of the pseudo physical cluster D is LCd, and the pseudo physical cluster address corresponding to the logical cluster address LCd in the LUT 56 is PCe. And
When the pseudo physical cluster addresses PCd and PCe are equal, it can be determined that the pseudo physical cluster D is a valid cluster, and when the pseudo physical cluster addresses PCd and PCe are not equal, it can be determined that the pseudo physical cluster D is an invalid cluster.
In other words, if the pseudo physical cluster address corresponding to the logical cluster address in the information stored by the pseudo physical cluster address specified by a certain pseudo physical cluster address of the LUT 56 matches the above pseudo physical cluster, the pseudo physical cluster is a valid cluster. If they do not match, the pseudo physical cluster is an invalid cluster.
For example, when a command to write the data DA1 to a certain logical cluster address LC1 is transmitted from the host 10, the write control unit 44 sends the data DA1 to one of the pseudo physical clusters (the pseudo physical cluster address of this cluster is PC1). To write.
The write control unit 44 sets the mapping between the logical cluster address LC1 and the pseudo physical cluster address PC1 in the LUT 56.
Thereafter, when a write command for overwriting the data DA2 with respect to the logical cluster address LC1 is transmitted from the host 10, the write control unit 44 transmits a pseudo physical cluster other than the previous pseudo physical cluster (this The data DA2 is written to the pseudo physical cluster address PC2).
The write control unit 44 sets the mapping between the logical cluster address LC1 and the pseudo physical cluster address PC2 in the LUT 56.
As a result, the pseudo physical cluster address PC1 is no longer specified from the LUT 56, and the pseudo physical cluster to which the data DA1 has been written (the pseudo physical cluster address is PC1) becomes an invalid cluster, and the data DA1 becomes invalid data.
As described above, invalid clusters are generated due to overwriting of data, and when physical blocks in which valid clusters and invalid clusters coexist increase, garbage is allocated to logical blocks including such physical blocks in order to effectively utilize the storage area. Collection processing is performed.
FIG. 4 is a flowchart illustrating an example of the garbage collection process.
The controller 22 (including the read control unit 42, the write control unit 44, and the GC control unit 46) determines in block 102 whether or not it is time to start garbage collection.
The controller 22 can determine whether it is time to start garbage collection based on whether a garbage collection command has been received from the host 10.
Also, since the controller 22 manages the state of the block, the controller 22 detects whether the number of physical blocks in which valid clusters and invalid clusters coexist has increased, and determines whether or not it is time to start garbage collection. Can be determined.
The controller 22 repeats the determination of the block 102 until it determines that it is time to start garbage collection.
When the controller 22 determines that the start timing of the garbage collection has been reached in the block 102, one of the logical blocks of the target candidate of the garbage collection including the physical block in which the valid cluster and the invalid cluster are mixed (block 104). Data is read from one pseudo physical cluster (referred to as GC source logical block).
The read data is stored in the read buffer 54.
In block 106, the controller 22 determines whether the data read in block 104 includes an uncorrectable read error.
When the read data includes a read error, the controller 22 corrects the read error.
However, some errors cannot be corrected by the controller 22 depending on the type and degree of the errors.
Since a cluster that generates a read error and stores data whose error cannot be corrected cannot be determined as a valid cluster or an invalid cluster, the data of the pseudo physical cluster cannot be moved to the GC-destination logical block.
When the controller 22 determines in block 106 that the read data includes an uncorrectable read error, the controller 22 manages the pseudo physical cluster as a logical unknown cluster in block 108.
If the controller 22 determines in block 106 that the read data does not include an uncorrectable read error, the controller 22 determines in block 110 whether the pseudo-physical cluster is a valid cluster.
This determination is performed based on where in the LUT 56 the logical cluster address of the redundant part of the pseudo physical cluster points, as described above.
If the controller 22 determines that the pseudo physical cluster is a valid cluster in block 110, the controller 22 writes data read from the valid cluster stored in the read buffer 54 to the pseudo physical cluster of the GC destination logical block in block 112.
The GC destination logical block is selected from logical blocks from which all data has been erased (also referred to as free blocks).
When the writing of the data to the GC destination logical block is completed in block 112, the pseudo physical cluster address in the GC source logical block in the LUT 56 is changed to the pseudo physical cluster address in the GC destination logical block, and the LUT 56 is updated.
After executing the processing of block 108 or block 112, or when determining in step 110 that the pseudo physical cluster is an invalid cluster, the controller 22 extracts data from all pseudo physical clusters in the GC source logical block in block 114. It is determined whether or not a read has been performed.
If the controller 22 determines in the block 114 that data has not been read from all the pseudo physical clusters in the GC source logical block, the controller 22 executes the block 104 again.
That is, the controller 22 reads data from another pseudo physical cluster in the GC source logical block, and repeats the same processing.
If the controller 22 determines in block 114 that data has been read from all pseudo physical clusters in the GC source logical block, the controller 22 determines in block 116 whether the GC source logical block includes a logic unknown cluster.
If the GC-source logical block does not include a logical unknown cluster, it can be determined that all data of the valid cluster in the GC-source logical block has been moved to the GC-destination logical block, and that the GC-source logical block can be erased.
If the GC-source logical block includes a logically unknown cluster, it is unknown whether all data of the valid cluster has been moved to the GC-destination logical block, and it can be determined that the GC-source logical block cannot be erased.
Therefore, when the controller 22 determines in the block 116 that the GC-source logical block does not include the logical unknown cluster, the controller 22 erases the data of all the physical blocks of the GC-source logical block in a block 118.
In block 122, the controller 22 sets the GC source logical block from which all data has been erased in block 118 as a candidate for the GC destination logical block, and ends the process.
If the controller 22 determines in block 116 that the GC-source logical block includes a logically unknown cluster, the controller 22 creates a new logical block in block 124 and erases data of all physical blocks allocated to the GC-source logical block. Then, the physical block from which data has been erased is assigned to the new logical block.
In block 126, the controller 22 sets the GC source logical block as a logical unknown block to which no physical block is allocated.
For example, the controller 22 sets all physical blocks allocated to the GC-source logical block as non-existent physical blocks.
When the logical block table 58 indicates the physical address of the physical block allocated to the logical block, an address not used as the physical address is written in the physical block column allocated to the GC source logical block in the logical block table 58.
As a result, when the host 10 attempts to read data in the logically unknown cluster, the data cannot be read because a pseudo physical cluster address corresponding to the logically unknown cluster address does not exist, and a read error is returned to the host 10.
In block 128, the controller 22 sets the new logical block as a candidate for the GC destination logical block, and ends the processing.
Note that the execution order of the blocks 126 and 128 may be reversed from that in FIG.
Although FIG. 4 illustrates an example in which the processing ends after block 128, the determination processing in block 102 is periodically executed, and when the garbage collection start timing comes, the processing in FIG. 4 is executed as an interrupt. May be.
The creation of a new logical block will be described with reference to FIG.
FIG. 5 shows an example of a state change of the logical block table 58 indicating the assignment relationship between the logical block addresses and the physical block addresses.
FIG. 5A shows the logical block table 58 before the execution of the block 124, for example, during the execution of the block 116.
FIG. 5B shows the logical block table 58 when the processing of the block 124 is completed.
FIG. 5C shows the logical block table 58 when the processing of the block 126 is completed.
It is assumed that (m + 1) logical blocks (logical blocks of logical block addresses LB0 to LBm) have been created.
The physical block specified by the physical block addresses PB0, PB1,... Is assigned to the logical block indicated by the logical block address LB0, and the physical block addresses PBi, PBi + 1,. .. Are assigned.
In FIG. 5, a physical block of a continuous physical block address is allocated to a logical block. However, this is merely an example, and even if a physical block of an arbitrary discrete physical block address is allocated to the logical block. good.
It is assumed that the logical block of the logical block address LBm is a GC source logical block (logical unknown block) including a logically unknown cluster.
It is assumed that the logical block address of the new logical block created in block 124 is LBm + 1, as shown in FIG.
As shown in FIG. 5C, the controller 22 addresses the physical block addresses of all the physical blocks corresponding to the GC source logical block specified by the logical block address LBm in the logical block table 58, as shown in FIG. Is a value that cannot exist as Null.
As a result, the GC source logical block is an unknown physical block.
An example of Null is "FF" for a 16-bit address.
As a result, when the host 10 attempts to read data in the logically unknown cluster, the data of the pseudo physical cluster corresponding to the logically unknown cluster cannot be read, and a read error is returned to the host 10.
At the timing of block 124, all the data of the valid cluster in the GC source logical block of the logical block address LBm has been moved to the GC destination logical block, and the data remaining in the GC source logical block is only the data of the logical unknown cluster. The data in the GC-source logical block is data that will not be read by the host 10 in the future or data that will not be returned to the host 10.
That is, the physical block allocated to the GC source logical block is an erasable physical block because it is not used in the future.
For this reason, in the block 124, the data of the physical block specified by the physical block addresses PBi, PBi + 1,... Assigned to the CG source logical block specified by the logical block address LBm is erased. Are assigned to the new logical block, and the erased new logical block can be used as the GC destination logical block.
As a result, even if there is a cluster of unknown logic, an erased GC destination logical block required for the garbage collection process can be secured, and a state in which the garbage collection process cannot be executed can be avoided.
Hereinafter, an operation example of the garbage collection for each specific situation will be described.
6 and 7 show an example in which the GC destination logical blocks are sequentially generated and the garbage collection is continuously executed.
The logical blocks BL0, BL1, BL2, BL4,... Have been programmed, and the logical block BL3 has been erased.
“Programmed” means that data has been written to such an extent that there is no room for writing new data.
The erased logical block BL3 can be a GC destination logical block.
Assume that valid clusters and invalid clusters are mixed in the programmed logical blocks BL0, BL1, BL2, BL4,..., And these logical blocks BL0, BL1, BL2, BL4,.
First, as shown in FIG. 6A, one of the candidates for the GC-source logical block, for example, the logical block BL0 is set as the GC-source logical block, and data is read from the GC-source logical block BL0 in units of pseudo physical clusters. If the pseudo physical cluster is a valid cluster, the read data is moved to the GC-destination logical block BL3.
The state of the GC destination logical block BL3 changes from being erased to during programming.
When the data read from all the valid clusters of the GC source logical block BL0 is moved to the GC destination logical block BL3, all the data of the GC source logical block BL0 is erased as shown in FIG. 6 (b).
The erased logical block BL0 can be a GC destination logical block.
Next, as shown in FIG. 6 (c), another one of the candidates of the GC-source logical block, for example, the logical block BL1 is set as the GC-source logical block, and the pseudo-physical cluster unit from the GC-source logical block BL1. When data is read and the pseudo physical cluster is a valid cluster, the read data is moved to the GC destination logical block BL3.
When the amount of data moved (written) to the GC destination logical block BL3 increases, the state of the GC destination logical block BL3 becomes programmed, as shown in FIG. Data cannot be moved to GC destination logical block BL3.
However, since there is an erased logical block BL0 that can be a GC destination logical block, thereafter, as shown in FIG. 7 (b), data read from the valid cluster of the GC source logical block BL1 is It moves to block BL0 and garbage collection continues.
When data is read from all valid clusters in the GC source logical block BL1 and data is moved to the GC destination logical block BL0, all data in the GC source logical block BL1 is erased as shown in FIG. 7 (c). Is done.
The erased logical block BL1 can be a GC destination logical block.
Thus, the garbage collection is continued as long as the erased logical block is newly generated.
Next, an example in which the execution of the garbage collection cannot be continued will be described with reference to FIGS.
As in the case of FIG. 6 (a), as shown in FIG. 8 (a), data read from the valid cluster of the GC source logical block BL0 is moved to the GC destination logical block BL3, and garbage collection is executed.
As shown in FIG. 8 (b), if data read from the pseudo physical cluster of the GC source logical block BL0 includes a read error during the garbage collection and the read error cannot be corrected, the cluster is a valid cluster. It cannot be determined that the cluster is an invalid cluster, and data read from the cluster cannot be moved to the GC-destination logical block BL3.
When the data read from all the valid clusters of the GC source logical block BL0 is moved to the GC destination logical block BL3, the logical block BL1 is set as the GC source logical block as shown in FIG. Data read from the valid cluster of the block BL1 is moved to the GC destination logical block BL3.
When the amount of data written to the GC destination logical block BL3 increases, the state of the GC destination logical block BL3 becomes programmed, as shown in FIG. Data cannot be moved to block BL3.
In the examples shown in FIGS. 6 and 7, since the erased logical block BL0 exists at this stage (FIG. 7A), the garbage collection for the GC-source logical block BL1 can be continued.
However, as shown in FIG. 9 (a), when the state of the GC destination logical block BL3 becomes programmed, there is no erased logical block, so as shown in FIG. 9 (b), There is no GC destination logical block to which data read from the valid cluster of the GC source logical block BL1 is moved, and it is impossible to continue garbage collection any more.
Note that after the occurrence of the uncorrectable read error shown in FIG. 8 (b), the state of the GC destination logical block BL3 shown in FIG. 9 (a) becomes programmed and there is no erased logical block. If the correspondence between all the logical addresses and the physical addresses of the LUT 56 is checked during the period until the state becomes uncorrected, the pseudo-physical cluster storing the data in which the uncorrectable read error has occurred is a valid cluster or an invalid cluster. Can be determined.
However, if the size of the LUT 56 is large, it is impossible to check the correspondence between all logical addresses and physical addresses of the LUT 56 during this period.
In order to avoid such a situation, it is conceivable to prepare in advance a large number of erased logical blocks that can be GC destination logical blocks.
FIG. 10 and FIG. 11 show examples of garbage collection when an erased logical block is prepared in advance.
The logical blocks BL0, BL1, BL2, BL4,... Have been programmed, and the logical blocks BL3, eBL0, eBL1,.
The erased logical blocks eBL0, eBL1,... Are used only as CG destination logical blocks and are not used for storing user data.
The erased logical blocks eBL0, eBL1,... May be logical blocks in which no user data has been stored, or may have stored user data. May be a logical block not used.
As shown in FIG. 10A, the data read from the valid cluster of the GC source logical block BL0 is moved to the GC destination logical block BL3.
The state of the GC destination logical block BL3 changes from being erased to during programming.
As shown in FIG. 10B, when data read from the pseudo physical cluster of the GC source logical block BL0 during the garbage collection is uncorrectable, the read data cannot be moved to the GC destination logical block BL3.
When the data read from all the valid clusters of the GC source logical block BL0 is moved to the GC destination logical block BL3, the logical block BL1 is set as the GC source logical block, as shown in FIG. Data read from the valid cluster of the block BL1 is moved to the GC destination logical block BL3.
If the amount of data written to the GC destination logical block BL3 increases, the state of the GC destination logical block BL3 becomes programmed as shown in FIG. Data cannot be moved to block BL3.
In the examples shown in FIGS. 8 and 9, as shown in FIGS. 9A and 9B, when the state of the GC-destination logical block BL3 becomes programmed, no erased logical block exists. No garbage collection could be continued because there were no.
However, in the examples shown in FIGS. 10 and 11, since the erased logical blocks eBL0, eBL1,... Which can be used as the GC destination logical blocks are prepared in advance, the garbage collection can continue even if a logical unknown block occurs. It is.
That is, as shown in FIG. 11 (a), when the state of the GC destination logical block BL3 changes from being programmed to programmed, as shown in FIG. 11 (b), the erased logical block eBL0 becomes the GC destination logical block. The data read from the valid cluster of the GC source logical block BL1 is moved to the GC destination logical block eBL0, and the garbage collection is continued.
When data is read from all valid clusters of the GC source logical block BL1 and data is moved to the GC destination logical block eBL0, all data of the GC source logical block BL1 is erased as shown in FIG. 11 (c). Is done.
The erased logical block BL1 can be a GC destination logical block.
As described above, by preparing the erased logical block in advance, even if a logical unknown block occurs, the possibility that the GC destination logical block is exhausted is reduced.
However, there is a disadvantage that the storage cost of the flash memory is increased due to the erased logical block prepared in advance.
In the examples of FIGS. 10 and 11, the period for checking the correspondence between all logical addresses and physical addresses of the LUT 56 and determining whether the logical unknown block is a valid cluster or an invalid cluster is shown in FIG. This is the period from the occurrence of the uncorrectable read error shown in b) to the disappearance of any erased logical block.
For this reason, compared to the case shown in FIGS. 8 and 9, the time is longer, and there is a time margin for examining the LUT 56 to determine whether the logical unknown block is a valid cluster or an invalid cluster. FIG. 13 shows a garbage collection operation that can prevent the GC destination logical block from being exhausted without preparing an erased logical block in advance.
As shown in FIG. 12A, data read from the valid cluster of the GC source logical block BL0 is moved to the GC destination logical block BL3.
As shown in FIG. 12 (b), when data read from the GC-source logical block BL0 cannot be corrected during the garbage collection, it cannot be determined whether the cluster is a valid cluster or an invalid cluster, and the data is read from the cluster. Data cannot be moved to GC destination logical block BL3.
When data read from all valid clusters of the GC source logical block BL0 is moved to the GC destination logical block BL3, a new logical block nBL0 is generated as shown in FIG. 12 (c).
The physical block allocated to the new logical block nBL0 is the physical block allocated to the GC-source logical block BL0, and its data has been erased.
At the same time, the GC-source logical block BL0 is changed to a logical unknown block to which no physical block is assigned.
Further, as shown in FIG. 12 (c), the logical block BL1 is set as a GC source logical block, and data read from a valid cluster of the GC source logical block BL1 is moved to the GC destination logical block BL3.
When the data written to the GC destination logical block BL3 increases, as shown in FIG. 13 (a), the state of the GC destination logical block BL3 becomes programmed, and data is transferred from the GC source logical block BL1 to the GC destination logical block BL3. Will be unable to move.
However, since the erased logical block nBL0 exists, even if a logical unknown block including a logical unknown cluster occurs, the GC destination logical block nBL0 can be secured, and as shown in FIG. Data read from the valid cluster is moved to the GC destination logical block nBL0.
When an uncorrectable read error does not occur during data reading of the GC source logical block BL1 and all data of the valid cluster of the GC source logical block BL1 is moved to the GC destination logical block nBL0, as shown in FIG. Thus, all data of the GC source logical block BL1 is erased, and the erased logical block BL1 can be a GC destination logical block.
According to the operations in FIGS. 12 and 13, when data is read from the pseudo physical cluster of the GC source logical block in the garbage collection, a read error occurs, and if the read error cannot be corrected, the GC source logical block is enabled. After data is moved from the cluster to the GC destination logical block, a new logical block is created.
After erasing the data of the physical block allocated to the GC source logical block, the erased physical block is allocated to the new logical block.
Thereby, the erased GC destination logical block can be secured.
The GC source logical block is a logical unknown block to which no physical block is assigned.
Since the data of the valid cluster of the GC source logical block is moved to the GC destination logical block, when a read command related to this data is transmitted from the host 10 to the controller 22 thereafter, the LUT 56 is set to the pseudo physical cluster in the GC destination logical block. Or, since it indicates a physical block, data is read from a pseudo physical cluster or a physical block in the GC destination logical block.
The data of invalid clusters and unknown logical clusters in the GC original logical block remain in the GC original logical block, but since the physical blocks are no longer allocated to the GC original logical block, data read from invalid clusters and logical unknown clusters will be performed thereafter. When the command is transmitted from the host 10 to the controller 22, the data is not read, and a read error is returned to the host 10.
In the controller 22, a physical read error indicating a pseudo physical cluster in which the LUT 56 does not exist is distinguished from a read error including an error in which data cannot be corrected. There is no distinction between the two errors.
The reason that a read error is returned in response to a read request related to a logical unknown cluster is the same even when a new logical block is not created.
Therefore, when an uncorrectable read error occurs, the operation of the SSD 20 as viewed from the host 10 is the same whether a new logical block is created or a new logical block is created.
According to the operations in FIGS. 12 and 13, there is no need to provide an erased logical block that can be used as a GC destination logical block in order to cope with a situation in which data of a GC source logical block including a logical unknown cluster cannot be erased.
When the size of one logical block is increased, the number of logical blocks is reduced, so that the GC-destination logical block is easily exhausted.
However, as shown in FIGS. 12 and 13, when a logic-unknown block occurs, a new logic block is created, so that the CG-destination logic block is hardly depleted.
Note that the present invention is not limited to the above-described embodiment as it is, and can be embodied by modifying constituent elements without departing from the gist thereof in an implementation stage.
Various inventions can be formed by appropriately combining a plurality of constituent elements disclosed in the above embodiments.
For example, some components may be deleted from all the components shown in the embodiment.
Further, components of different embodiments may be appropriately combined.
Description of symbols 10 ... Host, 20 ... SSD, 22 ... Controller, 24 ... NAND flash memory, 26 ... RAM, 42 ... Read control unit, 44 ... Write control unit, 46 ... GC control unit, 56 ... LUT, 58 ... Logical block table.
Document name Claims Claims have a plurality of physical blocks, each physical block has a plurality of clusters, data is erased in units of physical blocks, and data is read or written in units of clusters. A first table that stores a relationship between a logical address specified by a device and a physical address of the nonvolatile memory corresponding to the logical address, a logical block to which a plurality of physical blocks of the nonvolatile memory are assigned, The second table that stores the relationship with a plurality of physical blocks, and data read from all valid clusters of the garbage collection source logical block is moved to the garbage collection destination logical block, and all data of the garbage collection source logical block are moved. Erasing and updating the first table. When the data read from the cluster of the garbage collection source logical block is uncorrectable, the controller creates a new logical block and deletes all data of a plurality of physical blocks allocated to the garbage collection source logical block. A storage device for erasing, allocating the plurality of physical blocks from which data has been erased to the new logical block, and updating the second table so that a physical block is not substantially allocated to the garbage collection source logical block.
The controller updates the second table by allocating a physical block that cannot exist in the garbage collection source logical block so that a physical block is not substantially allocated to the garbage collection source logical block. A storage device as described.
A plurality of pseudo physical clusters are assigned to the logical block, one of the plurality of pseudo physical clusters stores user data and a logical cluster address, and the logical cluster address is the one pseudo physical cluster. The first table stores a pseudo physical cluster address corresponding to the logical cluster address, and the pseudo physical cluster address is the plurality of logical blocks including the one pseudo physical cluster. 2. The storage device according to claim 1, wherein the storage device includes information that specifies a relative position of the one pseudo physical cluster in the specified logical block.
The controller moves data read from the effective pseudo physical cluster of the garbage collection source logical block to the pseudo physical cluster of the garbage collection destination logical block, and stores the data in the logical address corresponding to the effective pseudo physical cluster in the first table. 4. The storage device according to claim 3, wherein the corresponding pseudo physical cluster address is changed to the address of the pseudo physical cluster of the garbage collection destination logical block.
When the second pseudo physical cluster address corresponding to the first logical cluster address stored by the first pseudo physical cluster specified by the first pseudo physical cluster address in the first table is equal to the first pseudo physical cluster address, The first pseudo physical cluster is an effective pseudo physical cluster, and if the second pseudo physical cluster address is not equal to the first pseudo physical cluster address, the first pseudo physical cluster is an invalid pseudo physical cluster. 5. Storage device.
The controller, after updating the second table, receives, from the external device, a read command related to the cluster of the garbage collection source logical block in which the read data is uncorrectable, and transmits information indicating a read error to the external device. 2. The storage device according to claim 1, wherein the storage device sends a reply.
It has a plurality of physical blocks, each physical block has a plurality of clusters, data is erased in physical block units, and data is read or written in cluster units. An address, a first table storing a relationship between physical addresses of the nonvolatile memory corresponding to the logical addresses, a logical block to which a plurality of physical blocks of the nonvolatile memory are assigned, and a The second table that stores the relationship and data read from all valid clusters of the garbage collection source logical block are moved to the garbage collection destination logical block, and all data of the garbage collection source logical block are erased. And a controller for updating the table. The method, if the data read from the cluster of the garbage collection source logical block is uncorrectable, the controller creates a new logical block and creates a new logical block of the plurality of physical blocks assigned to the garbage collection source logical block. Erasing all data, allocating the plurality of physical blocks from which data has been erased to the new logical block, and updating the second table so that physical blocks are not substantially allocated to the garbage collection source logical block Memory control method.
8. The controller according to claim 7, wherein the controller allocates a physical block that cannot exist in the garbage collection source logical block, thereby updating the second table so that a physical block is not substantially allocated to the garbage collection source logical block. The storage control method according to the above.
A plurality of pseudo physical clusters are assigned to the logical block, one of the plurality of pseudo physical clusters stores user data and a logical cluster address, and the logical cluster address is the one pseudo physical cluster. The first table stores a pseudo physical cluster address corresponding to the logical cluster address, and the pseudo physical cluster address is the plurality of logical blocks including the one pseudo physical cluster. 8. The storage control method according to claim 7, wherein the storage control method includes information that specifies the relative position of the one pseudo physical cluster in the specified logical block.
By the controller, data read from the effective pseudo physical cluster of the garbage collection source logical block is moved to the pseudo physical cluster of the garbage collection destination logical block, and the logical address corresponding to the effective pseudo physical cluster of the first table is moved to 10. The storage control method according to claim 9, wherein the corresponding pseudo physical cluster address is changed to the address of the pseudo physical cluster of the garbage collection destination logical block.
When the second pseudo physical cluster address corresponding to the first logical cluster address stored by the first pseudo physical cluster specified by the first pseudo physical cluster address in the first table is equal to the first pseudo physical cluster address, 10. The first pseudo physical cluster is a valid pseudo physical cluster, and if the second pseudo physical cluster address is not equal to the first pseudo physical cluster address, the first pseudo physical cluster is an invalid pseudo physical cluster. Storage control method.
The controller, after updating the second table, receives, from the external device, a read command related to the cluster of the garbage collection source logical block in which the read data is uncorrectable, and transmits information indicating a read error to the external device. 8. The storage control method according to claim 7, wherein a reply is made.
Abstract: Provided is a storage device and a storage control method capable of securing a GC source logical block and executing garbage collection even if an uncorrectable read error occurs.
According to an embodiment, a storage device includes a non-volatile memory, a first table storing a relationship between a logical address specified by an external device and a physical address of the non-volatile memory, a logical block and a plurality of physical blocks. And a controller for updating the first table by garbage collection.
If the data read from the cluster of the GC source logical block is uncorrectable, the controller creates a new logical block, erases all data in multiple physical blocks assigned to the GC source logical block, and erases the data The allocated plurality of physical blocks are allocated to the new logical block, and the second table is updated so that the physical block is not substantially allocated to the GC-source logical block.
